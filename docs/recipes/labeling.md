---
title: Labeling
chef: Allison Parrish
abstract: A method for hand-labeling textual units from a small corpus, then computationally rearranging them to create new juxtapositions and poetic texts.
description: >
  "Labeling" proposes a computational poetry practice grounded in close, personal
  attention to a small text rather than at the scale of machine learning. Instead of
  relying on automated tools to categorize language, the poet reads a short source
  text—a story, a handful of poems, journal entries—and manually labels its units
  according to categories they define themselves as the work progresses.

  The recipe contrasts this approach with industrial labeling for machine learning
  datasets, where categories are imposed in advance by institutions for profit. Here,
  categories emerge from the poet's own pleasure and curiosity: part of speech, weight
  (light vs. heavy), texture (hard vs. soft), abstraction (concrete vs. intangible).
  The goal is not to generalize over all of language but to discover new things about
  one particular text.

  Parrish offers three interlocking exercises. First, break the text into lines—along
  syntactic seams, by fixed word count, or even mid-word—and sort those lines by
  length or alphabetically using an online text tool or spreadsheet. Second, extract
  all unique words from the text into a spreadsheet, label them across multiple
  subjective columns, and filter or sort by those labels. Third, use spreadsheet
  randomization or a tool like Tracery to reassemble filtered word lists into new
  arrangements, creating juxtapositions of, for example, soft adjectives beside
  intangible nouns beside prepositional phrases.

  The result is poetry that differs from Dadaist chance operations because the poet's
  careful taxonomic choices constrain and inflect the randomness, preserving the
  character of the source text while lifting it into new contexts.
genres:
  - Word Manipulation
  - Machine reading
difficulty_pans: 1
yields: >
  A hand-labeled word database drawn from a short source text, plus rearranged poetic
  outputs generated by sorting, filtering, and randomly reordering labeled units via
  spreadsheet or computational text tools.
github_link: https://tracery.io/
---

## Ingredients

- A short source text (a story, a few poems, journal entries, or web-copied text)
- A spreadsheet program (Google Sheets, LibreOffice Calc, Microsoft Excel, or Numbers)
- An optional online text tool for splitting and sorting: e.g., [My Text Tools](https://www.mytexttools.com/) or [Voyant Tools](https://voyant-tools.org/)
- Optional: [Tracery](https://tracery.io/) for generative grammar-based reassembly

## Method

**Exercise 1: Line Breaks**

1. Choose your source text. If it is prose, introduce line breaks by making curatorial decisions: break at syntactic seams, at fixed word counts (e.g., every four words), or even mid-word.
2. Copy the resulting lines into a spreadsheet, one line per row.
3. Sort the rows by line length, alphabetically, or by any other attribute using the spreadsheet's sort function.
4. Read the sorted lines as a poem. Note which juxtapositions have energy.

**Exercise 2: Labeling Words**

1. Extract all unique words from your source text (manually or using an online tool). Place each word in its own row in a spreadsheet, under a column headed "word."
2. Add a second column for an objective attribute, such as "part of speech" (noun, verb, adjective, etc.).
3. Add a third column for a subjective attribute you define yourself: "light/heavy" (1–5), "hard/soft," "concrete/intangible," or any other scale that interests you.
4. Add as many additional columns as you like. Label slowly—this is good activity to do while listening to music or a podcast.
5. Once you have several hundred words labeled, use the spreadsheet's filter function to select subsets (e.g., only adjectives) and sort by your subjective scores to find the heaviest adjectives, the softest nouns, the most intangible verbs.

**Exercise 3: Arrangement**

1. Copy filtered lists (e.g., soft adjectives, intangible nouns, prepositional phrases) into a new spreadsheet, each list in its own column.
2. Randomize the order of each column independently using your spreadsheet's "shuffle" or "sort randomly" feature.
3. Read the columns left to right as lines of a poem. Juxtapositions emerge from the poet's categories, not pure chance.
4. Alternatively, load your word lists into [Tracery](https://tracery.io/) to build a recursive grammar that generates new sentences from your labeled categories.

## Notes

- The unit need not be the word: you can apply the same labeling process to lines, sentences, clauses, or phrases.
- The labeling process is itself a form of close reading. The categories you invent reveal as much about you as about the text.
- Unlike Dadaist cut-up, which treats all units as interchangeable, labeling preserves the poet's curation: the randomness operates within constraints shaped by careful attention to the source.
- Related tool: [Voyant Tools](https://voyant-tools.org/) can help generate word frequency lists as a starting point for your unique-words column.
